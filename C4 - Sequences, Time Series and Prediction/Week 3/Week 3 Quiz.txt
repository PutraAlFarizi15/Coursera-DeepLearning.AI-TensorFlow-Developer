1.
Question 1
If X is the standard notation for the input to an RNN, what are the standard notations for the outputs?

1 / 1 point

Y


H


* Y(hat) and H


H(hat) and Y


Correct
2.
Question 2
What is a sequence to vector if an RNN has 30 cells numbered 0 to 29

1 / 1 point

The average Y(hat) for all 30 cells


The Y(hat) for the second cell


* The Y(hat) for the last cell


The total Y(hat) for all cells

Correct
3.
Question 3
What does a Lambda layer in a neural network do?

1 / 1 point

There are no Lambda layers in a neural network


Pauses training without a callback


* Allows you to execute arbitrary code while training


Changes the shape of the input or output data

Correct
4.
Question 4
What does the axis parameter of tf.expand_dims do?

1 / 1 point

* Defines the dimension index at which you will expand the shape of the tensor 


Defines if the tensor is X or Y


Defines the dimension index to remove when you expand the tensor


Defines the axis around which to expand the dimensions

Correct
5.
Question 5
A new loss function was introduced in this module, named after a famous statistician. What is it called?

1 / 1 point

Hubble loss


Hawking loss


* Huber loss


Hyatt loss

Correct
6.
Question 6
Whatâ€™s the primary difference between a simple RNN and an LSTM

1 / 1 point

In addition to the H output, RNNs have a cell state that runs across all cells 


* In addition to the H output, LSTMs have a cell state that runs across all cells 


LSTMs have a single output, RNNs have multiple


LSTMs have multiple outputs, RNNs have a single one

Correct
7.
Question 7
If you want to clear out all temporary variables that tensorflow might have from previous sessions, what code do you run?

1 / 1 point

tf.cache.backend.clear_session()


tf.cache.clear_session()


tf.keras.clear_session


* tf.keras.backend.clear_session()  

Correct
8.
Question 8
What happens if you define a neural network with these two layers?


tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),

tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),

tf.keras.layers.Dense(1),

1 / 1 point

* Your model will fail because you need return_sequences=True after the first LSTM layer


Your model will compile and run correctly


Your model will fail because you have the same number of cells in each LSTM


Your model will fail because you need return_sequences=True after each LSTM layer